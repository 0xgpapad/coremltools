{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While converting to CoreML there is an option to set image preprocessing parameters. Channel wise bias and an overall scale is supported, which is quite common. However, some models may require a per channel scale parameter. \n",
    "This can be implemented by adding a \"scale\" layer in the beginning of the network, after conversion. Let us see how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : cropping2d_4_input, <keras.engine.topology.InputLayer object at 0x120f17290>\n",
      "1 : cropping2d_4, <keras.layers.convolutional.Cropping2D object at 0x120f17250>\n"
     ]
    }
   ],
   "source": [
    "# Define a toy Keras network and convert to CoreML\n",
    "input_shape = (50, 50, 3)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((5,5),(5,5)), input_shape=input_shape))\n",
    "\n",
    "mlmodel = coremltools.converters.keras.convert(model,\n",
    "                                              image_input_names='input1',\n",
    "                                              red_bias=-10.0, \n",
    "                                              green_bias=-10.0, \n",
    "                                              blue_bias=-10.0,\n",
    "                                              image_scale=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {\n",
      "  name: \"input1\"\n",
      "  type {\n",
      "    imageType {\n",
      "      width: 50\n",
      "      height: 50\n",
      "      colorSpace: RGB\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"output1\"\n",
      "  type {\n",
      "    multiArrayType {\n",
      "      shape: 3\n",
      "      shape: 40\n",
      "      shape: 40\n",
      "      dataType: DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec = mlmodel.get_spec()\n",
    "print(spec.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('output along channel at [0,0]: ', array([490., 490., 490.]))\n"
     ]
    }
   ],
   "source": [
    "# Lets call predict with an all constant image input\n",
    "x = 100.0 * np.ones((3,50,50))\n",
    "x = x.astype(np.uint8)\n",
    "x_transpose = np.transpose(x, [1,2,0]) # PIL Image requires the format to be [H,W,C]\n",
    "im = Image.fromarray(x_transpose)\n",
    "\n",
    "y = mlmodel.predict({'input1': im}, useCPUOnly=True)['output1']\n",
    "print('output along channel at [0,0]: ', y[:,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
